{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchsummary import summary\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "# compute the current classification accuracy\n",
    "def compute_acc(preds, labels):\n",
    "    correct = 0\n",
    "    preds_ = preds.data.max(1)[1]\n",
    "    correct = preds_.eq(labels.data).cpu().sum()\n",
    "    acc = float(correct) / float(len(labels.data)) * 100.0\n",
    "    return acc\n",
    "\n",
    "class Generator_128(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator_128, self).__init__()\n",
    "        self.fc1 = nn.Linear(110, 384)\n",
    "        \n",
    "        self.transConv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=384, out_channels=192, kernel_size=4, stride=1,padding=0,bias=False),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=192, out_channels=96, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=96, out_channels=48, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=48, out_channels=24, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=24, out_channels=12, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=12, out_channels=3, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "#         self.apply(weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 110)\n",
    "        fc1 = self.fc1(x)\n",
    "        fc1 = fc1.view(-1, 384, 1, 1)\n",
    "        transconv1 = self.transConv1(fc1)\n",
    "        transconv2 = self.transConv2(transconv1)\n",
    "        transconv3 = self.transConv3(transconv2)\n",
    "        transconv4 = self.transConv4(transconv3)\n",
    "        transconv5 = self.transConv5(transconv4)\n",
    "        transconv6 = self.transConv6(transconv5)\n",
    "        return transconv6\n",
    "    \n",
    "class Generator_64(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator_64, self).__init__()\n",
    "        self.fc1 = nn.Linear(110, 384)\n",
    "        \n",
    "        self.transConv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=384, out_channels=192, kernel_size=4, stride=1,padding=0,bias=False),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=192, out_channels=96, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=96, out_channels=48, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=48, out_channels=24, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=24, out_channels=3, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "#         self.transConv6 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(in_channels=12, out_channels=3, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "#         self.apply(weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 110)\n",
    "        fc1 = self.fc1(x)\n",
    "        fc1 = fc1.view(-1, 384, 1, 1)\n",
    "        transconv1 = self.transConv1(fc1)\n",
    "        transconv2 = self.transConv2(transconv1)\n",
    "        transconv3 = self.transConv3(transconv2)\n",
    "        transconv4 = self.transConv4(transconv3)\n",
    "        transconv5 = self.transConv5(transconv4)\n",
    "        return transconv5\n",
    "\n",
    "class Generator_32(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator_32, self).__init__()\n",
    "        self.fc1 = nn.Linear(110, 384)\n",
    "        \n",
    "        self.transConv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=384, out_channels=192, kernel_size=4, stride=1,padding=0,bias=False),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=192, out_channels=96, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=96, out_channels=48, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.transConv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=48, out_channels=3, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "#         self.transConv5 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(in_channels=24, out_channels=3, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "#         self.transConv6 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(in_channels=12, out_channels=3, kernel_size=4, stride=2,padding=1,bias=False),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "#         self.apply(weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 110)\n",
    "        fc1 = self.fc1(x)\n",
    "        fc1 = fc1.view(-1, 384, 1, 1)\n",
    "        transconv1 = self.transConv1(fc1)\n",
    "        transconv2 = self.transConv2(transconv1)\n",
    "        transconv3 = self.transConv3(transconv2)\n",
    "        transconv4 = self.transConv4(transconv3)\n",
    "        return transconv4\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, num_labels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.Conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.5, inplace=False)\n",
    "        )\n",
    "        self.Conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.5, inplace=False)\n",
    "        )\n",
    "        self.Conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.5, inplace=False)\n",
    "        )\n",
    "        self.Conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.5, inplace=False)\n",
    "        )\n",
    "        self.Conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.5, inplace=False)\n",
    "        )\n",
    "        self.Conv6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.5, inplace=False)\n",
    "        )\n",
    "        self.fc_aux = nn.Linear(in_features=512*int(input_size / 8)*int(input_size / 8), out_features=num_labels)\n",
    "        self.fc = nn.Linear(512*int(input_size / 8)*int(input_size / 8), 1)\n",
    "        self._softmax = nn.Softmax()\n",
    "        self._sigmoid = nn.Sigmoid()\n",
    "#         self.apply(weights_init)\n",
    "    def forward(self, x):\n",
    "        x = self.Conv1(x)\n",
    "        x = self.Conv2(x)\n",
    "        x = self.Conv3(x)\n",
    "        x = self.Conv4(x)\n",
    "        x = self.Conv5(x)\n",
    "        x = self.Conv6(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        aux = self._softmax(self.fc_aux(x))\n",
    "        fc = self._sigmoid(self.fc(x)).view(-1, 1).squeeze(1)\n",
    "        return fc, aux\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "input_size = 110\n",
    "num_classes = 10\n",
    "image_size = 32\n",
    "EPOCH = 500\n",
    "noise_sd = 1.0\n",
    "LR = 0.0002\n",
    "\n",
    "evaluation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Discriminator(input_size = image_size, num_labels=10).to(device)\n",
    "# summary(model, input_size=(3,image_size,image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Generator_32().to(device)\n",
    "# summary(model, input_size=(1, 110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train for final model\n",
      "Learning rate: 0.0002, noise sd: 1.0\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "#         transforms.RandomCrop(image_size, padding=4),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "\n",
    "])\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# netD = _netD_CIFAR10(num_labels=10).to(device)\n",
    "# netG = _netG_CIFAR10().to(device)\n",
    "if evaluation is True:\n",
    "    netG = Generator_32().to(device)\n",
    "    save_folder = \"./modelv0/\"\n",
    "    image_folder = \"./imagev0/\"\n",
    "    log_file = os.path.join(save_folder, 'log_file.txt')\n",
    "    print('train for final model')\n",
    "else:\n",
    "    if image_size == 32:\n",
    "        netG = Generator_32().to(device)\n",
    "        root = './size32_lr%.4f' % LR\n",
    "        modelname = 'modelsd%.1f' % noise_sd\n",
    "        imagename = 'imagesd%.1f' % noise_sd\n",
    "        image_folder = os.path.join(root, imagename)\n",
    "        save_folder = os.path.join(root, modelname)\n",
    "        log_file = os.path.join(root, modelname, 'log_file.txt')\n",
    "#     if LR == 0.0002:\n",
    "#         netG = Generator_32().to(device)\n",
    "#         root = './size32'\n",
    "#         image_folder = \"./size32/image/\"\n",
    "#         save_folder = \"./size32/model/\"\n",
    "#         log_file = './size32/model/log_file.txt'\n",
    "#     elif LR == 0.0001:\n",
    "#         netG = Generator_32().to(device)\n",
    "#         image_folder = \"./size32_lr0.0001/image/\"\n",
    "#         save_folder = \"./size32_lr0.0001/model/\"\n",
    "#         log_file = './size32_lr0.0001/model/log_file.txt'\n",
    "    \n",
    "# if image_size == 64:\n",
    "#     netG = Generator_64().to(device)\n",
    "#     image_folder = \"./size64/image/\"\n",
    "#     save_folder = \"./size64/model/\"\n",
    "#     log_file = './size64/model/log_file.txt'\n",
    "# if image_size == 128:\n",
    "#     netG = Generator_128().to(device)\n",
    "#     image_folder = \"./size128/image/\"\n",
    "#     save_folder = \"./size128/model/\"\n",
    "#     log_file = './size128/model/log_file.txt'\n",
    "\n",
    "netD = Discriminator(input_size = image_size, num_labels=10).to(device)\n",
    "# netG = Generator_32().to(device)\n",
    "netD.apply(weights_init)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "\n",
    "\n",
    "_input = torch.FloatTensor(batch_size, 3, image_size, image_size).to(device)\n",
    "noise = torch.FloatTensor(batch_size, 110, 1, 1).to(device)\n",
    "eval_noise = torch.FloatTensor(batch_size, 110, 1, 1).normal_(0, noise_sd).to(device)\n",
    "dis_label = torch.FloatTensor(batch_size).to(device)\n",
    "aux_label = torch.LongTensor(batch_size).to(device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# noise for evaluation\n",
    "eval_noise_ = np.random.normal(0, 1, (batch_size, 110))\n",
    "eval_label = np.random.randint(0, num_classes, batch_size)\n",
    "eval_onehot = np.zeros((batch_size, num_classes))\n",
    "eval_onehot[np.arange(batch_size), eval_label] = 1\n",
    "eval_noise_[np.arange(batch_size), :num_classes] = eval_onehot[np.arange(batch_size)]\n",
    "eval_noise_ = (torch.from_numpy(eval_noise_))\n",
    "eval_noise.data.copy_(eval_noise_.view(batch_size, 110, 1, 1))\n",
    "\n",
    "dis_criterion = nn.BCELoss()\n",
    "aux_criterion = nn.NLLLoss()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "print('Learning rate: %.4f, noise sd: %.1f' %(LR, noise_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jikai/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:206: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "avg_loss_D = 0.0\n",
    "avg_loss_G = 0.0\n",
    "avg_loss_A = 0.0\n",
    "loss_D, loss_G, loss_A = [], [], []\n",
    "\n",
    "\n",
    "f = open(log_file, 'w')\n",
    "for epoch in range(EPOCH):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu, label = data\n",
    "        batch_size = real_cpu.size(0)\n",
    "        real_cpu = real_cpu.to(device)\n",
    "        label = label.to(device)\n",
    "        _input.data.resize_as_(real_cpu).copy_(real_cpu)\n",
    "        dis_label.data.resize_(batch_size).fill_(real_label)\n",
    "        aux_label.data.resize_(batch_size).copy_(label)\n",
    "        dis_output, aux_output = netD(_input)\n",
    "\n",
    "        dis_errD_real = dis_criterion(dis_output, dis_label)\n",
    "        aux_errD_real = aux_criterion(aux_output, aux_label)\n",
    "        errD_real = dis_errD_real + aux_errD_real\n",
    "        errD_real.backward()\n",
    "        D_x = dis_output.data.mean()\n",
    "\n",
    "        # compute the current classification accuracy\n",
    "        accuracy = compute_acc(aux_output, aux_label)\n",
    "\n",
    "        # train with fake\n",
    "        noise.data.resize_(batch_size, 110, 1, 1).normal_(0, noise_sd)\n",
    "        label = np.random.randint(0, num_classes, batch_size)\n",
    "        noise_ = np.random.normal(0, noise_sd, (batch_size, 110))\n",
    "        class_onehot = np.zeros((batch_size, num_classes))\n",
    "        class_onehot[np.arange(batch_size), label] = 1\n",
    "        noise_[np.arange(batch_size), :num_classes] = class_onehot[np.arange(batch_size)]\n",
    "        noise_ = (torch.from_numpy(noise_))\n",
    "        noise.data.copy_(noise_.view(batch_size, 110, 1, 1))\n",
    "        aux_label.data.resize_(batch_size).copy_(torch.from_numpy(label))\n",
    "\n",
    "        fake = netG(noise)\n",
    "        dis_label.data.fill_(fake_label)\n",
    "        dis_output, aux_output = netD(fake.detach())\n",
    "        dis_errD_fake = dis_criterion(dis_output, dis_label)\n",
    "        aux_errD_fake = aux_criterion(aux_output, aux_label)\n",
    "        errD_fake = dis_errD_fake + aux_errD_fake\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = dis_output.data.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        dis_label.data.fill_(real_label)  # fake labels are real for generator cost\n",
    "        dis_output, aux_output = netD(fake)\n",
    "        dis_errG = dis_criterion(dis_output, dis_label)\n",
    "        aux_errG = aux_criterion(aux_output, aux_label)\n",
    "        errG = dis_errG + aux_errG\n",
    "        errG.backward()\n",
    "        D_G_z2 = dis_output.data.mean()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # compute the average loss\n",
    "        curr_iter = epoch * len(trainloader) + i\n",
    "        all_loss_G = avg_loss_G * curr_iter\n",
    "        all_loss_D = avg_loss_D * curr_iter\n",
    "        all_loss_A = avg_loss_A * curr_iter\n",
    "#         all_loss_G += errG.data[0]\n",
    "#         all_loss_D += errD.data[0]\n",
    "        all_loss_G += errG.item()\n",
    "        all_loss_D += errD.item()\n",
    "        all_loss_A += accuracy\n",
    "        avg_loss_G = all_loss_G / (curr_iter + 1)\n",
    "        avg_loss_D = all_loss_D / (curr_iter + 1)\n",
    "        avg_loss_A = all_loss_A / (curr_iter + 1)\n",
    "        loss_A.append(avg_loss_A)\n",
    "        loss_G.append(avg_loss_G)\n",
    "        loss_D.append(avg_loss_D)\n",
    "\n",
    "        f.write('[%d/%d][%d/%d] Loss_D: %.4f (%.4f) Loss_G: %.4f (%.4f) D(x): %.4f D(G(z)): %.4f / %.4f Acc: %.4f (%.4f) \\n'\n",
    "              % (epoch, EPOCH, i, len(trainloader),\n",
    "                 errD.item(), avg_loss_D, errG.item(), avg_loss_G, D_x, D_G_z1, D_G_z2, accuracy, avg_loss_A))\n",
    "        if epoch % 100 == 0:\n",
    "            torchvision.utils.save_image(\n",
    "                real_cpu, '%s/real_samples_%03d.png' % (image_folder, epoch), nrow=10)\n",
    "        if i % 100 == 0:\n",
    "#             print('Label for eval = {}'.format(eval_label))\n",
    "            fake = netG(eval_noise)\n",
    "            torchvision.utils.save_image(\n",
    "                fake.data,\n",
    "                '%s/fake_samples_epoch_%03d.png' % (image_folder, epoch), \n",
    "                nrow=10\n",
    "            )\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (save_folder, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (save_folder, epoch))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jikai/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/jikai/anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py:128: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.arange(len(loss_A))\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(X, loss_A, label = \"aux\")\n",
    "plt.plot(X, loss_G, label = \"gen\")\n",
    "plt.plot(X, loss_D, label = \"disc\")\n",
    "plt.legend()\n",
    "if evaluation is True:\n",
    "    plt.title(\"Loss function of Final ACGAN, lr = %.4f, sd=%.1f\" % (LR, noise_sd))\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig('./plots/finalloss32_lr%.4f, sd=%.1f_v0.png' % (LR, noise_sd))\n",
    "else:\n",
    "    plt.title(\"Loss function of ACGAN, lr = %.4f, sd=%.1f\" % (LR, noise_sd))\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig('./plots/loss32_lr%.4f, sd=%.1f.png' % (LR, noise_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_images(genmod, l, num_classes, noise_sd, postfix):\n",
    "    random.seed(123)\n",
    "    torch.manual_seed(123)\n",
    "    k = int(l * num_classes)\n",
    "    noise = torch.FloatTensor(k, 110, 1, 1).to(device)\n",
    "    label = np.concatenate([np.repeat([0], l), np.repeat([1], l), np.repeat([2], l), np.repeat([3], l), \n",
    "                            np.repeat([4], l), np.repeat([5], l), np.repeat([6], l), np.repeat([7], l), \n",
    "                            np.repeat([8], l), np.repeat([9], l)])\n",
    "    noise_ = np.random.normal(0, noise_sd, (k, 110))\n",
    "    class_onehot = np.zeros((k, num_classes))\n",
    "    class_onehot[np.arange(k), label] = 1\n",
    "    noise_[np.arange(k), :num_classes] = class_onehot[np.arange(k)]\n",
    "    noise_ = (torch.from_numpy(noise_))\n",
    "    noise.data.copy_(noise_.view(k, 110, 1, 1))\n",
    "    fake = genmod(noise)\n",
    "   \n",
    "    torchvision.utils.save_image(\n",
    "                fake.data,\n",
    "                './test_image/example_%s.png' % postfix,\n",
    "                nrow=l\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Generator_32().to(device)\n",
    "# model.load_state_dict(torch.load(os.path.join('./size32_lr0.0001/modelsd0.1', \"netG_epoch_99.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postfix = 'lr0.0001 sd0.1' \n",
    "# get_sample_images(genmod=model, l=4, num_classes=num_classes, noise_sd=noise_sd, postfix=postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_folder = \"./model/\"\n",
    "model = Generator_32().to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(save_folder, \"netG_epoch_999.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = [0, 299, 499, 799, 999]\n",
    "model = Generator_32().to(device)\n",
    "for epoch in epoch_num:\n",
    "    mname = \"netG_epoch_%d.pth\" % epoch\n",
    "    model.load_state_dict(torch.load(os.path.join(save_folder, mname)))\n",
    "    postfix = 'final_epoch%d' % epoch\n",
    "    get_sample_images(genmod=model, l=4, num_classes=num_classes, noise_sd=noise_sd, postfix=postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if evaluation is True:\n",
    "    postfix = 'final lr%.4f sd%.1f_v0' % (LR, noise_sd)\n",
    "else:\n",
    "    postfix = 'lr%.4f sd%.1f' % (LR, noise_sd)\n",
    "get_sample_images(genmod=model, l=4, num_classes=num_classes, noise_sd=noise_sd, postfix=postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('plane',\n",
       " 'car',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
